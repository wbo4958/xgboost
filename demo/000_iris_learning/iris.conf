# General Parameters, see comment for each definition
# choose the booster, can be gbtree or gblinear
booster = gbtree
# choose logistic regression loss function for binary classification
objective = multi:softprob

tree_method = gpu_hist

# Tree Booster Parameters
# step size shrinkage
eta = 1.0
# minimum loss reduction required to make a further partition
gamma = 1.0
# minimum sum of instance weight(hessian) needed in a child
min_child_weight = 1
# maximum depth of a tree
max_depth = 3

num_class=3

#subsample=0.8

# Task Parameters
# the number of round to do boosting
num_round = 1
# 0 means do not save any model except the final round model
save_period = 0
# The path of training data
max_bin = 8
#train_path = "/home/bobwang/work.d/nvspark/30/dmlc.xgboost/xgboost/demo/000_iris_learning/iris.1.column.csv?format=csv&label_column=1"
train_path = "/home/bobwang/work.d/nvspark/30/dmlc.xgboost/xgboost/demo/000_iris_learning/iris.2.column.csv?format=csv&label_column=2"
#train_path = "/home/bobwang/work.d/nvspark/30/dmlc.xgboost/xgboost/demo/000_iris_learning/iris.transformed.csv?format=csv&label_column=4"
test:data= "/home/bobwang/work.d/nvspark/30/dmlc.xgboost/xgboost/demo/000_iris_learning/iris.2.column.csv?format=csv&label_column=2"
